{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Week 3 Introduction to image processing assignment"
      ],
      "metadata": {
        "id": "i1jC0a9JPdXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# importing the required libraries"
      ],
      "metadata": {
        "id": "eFMMkuVbTk-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom\n",
        "import pydicom\n",
        "import numpy as np \n",
        "import glob \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import json \n",
        "from ipywidgets import interact, interactive\n",
        "from typing import List, Tuple, Union"
      ],
      "metadata": {
        "id": "BQO2PIXmFIIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b542ee3f-8856-448c-a949-0133c57892f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydicom\n",
            "  Downloading pydicom-2.3.1-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# downloading the data\n",
        "#### In this section we are going to download a public dataset and unzip it for later usage. "
      ],
      "metadata": {
        "id": "-kMpNRj9Tnuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget --no-check-certificate https://data.idoimaging.com/dicom/1010_brain_mr/1010_brain_mr_04_lee.zip\n",
        "! unzip 1010_brain_mr_04_lee.zip"
      ],
      "metadata": {
        "id": "U9R1LNF9VdFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd937912-c8d1-4435-a938-5737dc06188f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-14 07:50:08--  https://data.idoimaging.com/dicom/1010_brain_mr/1010_brain_mr_04_lee.zip\n",
            "Resolving data.idoimaging.com (data.idoimaging.com)... 52.84.52.23, 52.84.52.21, 52.84.52.46, ...\n",
            "Connecting to data.idoimaging.com (data.idoimaging.com)|52.84.52.23|:443... connected.\n",
            "WARNING: cannot verify data.idoimaging.com's certificate, issued by ‘CN=Amazon,OU=Server CA 1B,O=Amazon,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2212367 (2.1M) [application/zip]\n",
            "Saving to: ‘1010_brain_mr_04_lee.zip’\n",
            "\n",
            "1010_brain_mr_04_le 100%[===================>]   2.11M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2023-04-14 07:50:08 (23.3 MB/s) - ‘1010_brain_mr_04_lee.zip’ saved [2212367/2212367]\n",
            "\n",
            "Archive:  1010_brain_mr_04_lee.zip\n",
            "   creating: 1010_brain_mr_04_lee/\n",
            "  inflating: 1010_brain_mr_04_lee/img_000.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_001.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_002.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_003.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_004.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_005.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_006.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_007.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_008.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_009.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_010.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_011.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_012.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_013.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_014.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_015.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_016.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_017.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_018.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_019.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_020.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_021.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_022.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_023.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_024.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_025.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_026.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_027.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_028.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_029.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_030.dcm  \n",
            "  inflating: 1010_brain_mr_04_lee/img_031.dcm  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '1010_brain_mr_04_lee'"
      ],
      "metadata": {
        "id": "OIzLZyKxFB_y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Excercise 1: Read Dicom files from a directory. \n",
        "For this question, you need to read all the `.dcm` files inside the provided directory slice by slice, and return the loaded slices in a format of a single `Numpy List` variable. \n",
        "\n",
        "* Define a function for reading the DICOM files and sort them based on their `instance numbers`\n",
        "* Access the patient ID from the dicom object using the following ways and print them: \n",
        "  - indexing \n",
        "  - attributes (tags)"
      ],
      "metadata": {
        "id": "mexiti9ZTqbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# solution\n",
        "def load_dicom_slices(dir_path: str, force: bool=False):\n",
        "  \"\"\" Load and sort a series of dicom files inside the provided folder path. \n",
        "  \"\"\"\n",
        "  files = os.listdir(dir_path)\n",
        "  slices = []\n",
        "  for file in files:\n",
        "      if file.endswith('.dcm'):\n",
        "          ds = pydicom.dcmread(os.path.join(dir_path, file))\n",
        "          slices.append(ds)\n",
        "\n",
        "  slices.sort(key=lambda x: int(x.InstanceNumber))\n",
        "  return slices\n",
        "\n",
        "slices = load_dicom_slices(dir_path)\n",
        "print(\"Number of slices: \", len(slices))\n",
        "print('Slices dtype: ', type(slices[0]))"
      ],
      "metadata": {
        "id": "_tTsBRxDATK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf245bf-4346-4f05-e141-9182c632c6aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of slices:  32\n",
            "Slices dtype:  <class 'pydicom.dataset.FileDataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing slices shape. \n",
        "print(\"Volume Shape (Row, Column): \", slices[0].Rows, slices[0].Rows)"
      ],
      "metadata": {
        "id": "Q65yRCc8HfHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interactive slides for viewing dicom slides\n",
        "plt.figure(1, figsize=(10, 10))\n",
        "def dicom_animation(x):\n",
        "    plt.imshow(slices[x].pixel_array, cmap=plt.cm.bone)\n",
        "    plt.colorbar()\n",
        "    return x\n",
        "\n",
        "interact(dicom_animation, x=(0, len(slices)-1))"
      ],
      "metadata": {
        "id": "AenqwpH7fHkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing the patient id. \n",
        "# Access the patient ID using indexing:\n",
        "patient_id = slices[0].PatientID\n",
        "print(\"Patient ID: \",patient_id)\n",
        "\n",
        "# Access the patient ID using attributes (tags):\n",
        "patient_id = slices[0].get(\"PatientID\")\n",
        "print(\"Patient ID: \",patient_id)"
      ],
      "metadata": {
        "id": "90vp7XOST5k9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f3c9be-045e-4cfc-b808-3e93c48c1b8f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient ID:  1010\n",
            "Patient ID:  1010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2: \n",
        "#### For this exercise you need to implement four function and try applying them on the loaded slices. \n",
        "* Define a function named `to_hu` for transforming the slices into Hounsfield scale. \n",
        "* Define a function named `window_clip` for cliping the pixel intensity range of each slice using a single center and windows width. Defined window describes your interested intensity range. \n",
        "* Define a function named `to_3d_numpy` to convert all the slices into a single Numpy ndarray image. This function is able to change the datatype of the output image if the user likes to change the new image datatype. \n",
        "* Define a function named `min_max_scaler` to scale a Numpy array into range `0` and `1` for easier visualization with matplotlib. This function is able to change the datatype (optional dtype by user) of the output image to `float`. \n",
        "\n"
      ],
      "metadata": {
        "id": "zY1MJ-r8MwM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_hu(slices):\n",
        "    \"\"\"\n",
        "    Transforms a list of DICOM datasets into Hounsfield units (HU).\n",
        "    :param dicom_datasets: A list of PyDICOM datasets to be transformed.\n",
        "    :return: A list of transformed datasets as NumPy arrays.\n",
        "    \"\"\"\n",
        "    hu_slices = []\n",
        "    intercept = slices[0].RescaleIntercept if 'RescaleIntercept' in slices[0] else 0\n",
        "    slope = slices[0].RescaleSlope if 'RescaleSlope' in slices[0] else 1\n",
        "    for ds in slices:\n",
        "        hu = ds.pixel_array * slope + intercept\n",
        "        hu_slices.append(hu)\n",
        "    return hu_slices"
      ],
      "metadata": {
        "id": "s_xL45dG0N9e"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GmZdVylV8shP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_hu(slices: List):\n",
        "    \"\"\"Transform a list of slices to a Hounsfield Unit Scale. \n",
        "    This function takes the loaded slices and return a list of transformed Numpy array format slices. \n",
        "    \"\"\"\n",
        "    hu_slices = []\n",
        "    intercept = slices[0].RescaleIntercept if 'RescaleIntercept' in slices[0] else 0\n",
        "    slope = slices[0].RescaleSlope if 'RescaleSlope' in slices[0] else 1\n",
        "    for sli in slices: \n",
        "      hu_image = sli.pixel_array * slope + intercept\n",
        "      hu_slices.append(hu_image) \n",
        "    return hu_slices\n",
        "\n",
        "def window_clip(slices: List, window_cent: int, window_width: int):\n",
        "    \"\"\"Clip a list of slices pixels, one by one, into a specific intensity range based on the provided window location and size.\n",
        "    All the pixels inside each single slice with a intensity below and over the window range will be clipped into the min and max intensity range window covers. \n",
        "    This function returns a list of clipped Numpy array slices. \n",
        "    \"\"\"\n",
        "    cliped_slices = []\n",
        "    for sli in slices:\n",
        "      clipped = np.clip(sli, window_cent - (window_width/2), window_cent + (window_width/2))\n",
        "      cliped_slices.append(clipped)\n",
        "    return cliped_slices\n",
        "    \n",
        "\n",
        "def to_3d_numpy(slices: List, dtype=None): \n",
        "    \"\"\"Stack up all slices into a single NumPy array of the provided data type.\n",
        "    \"\"\"\n",
        "    image = np.stack(slices)\n",
        "    if dtype: \n",
        "        image = image.astype(dtype)\n",
        "    return image\n",
        "\n",
        "def min_max_scaler(image: np.ndarray, dtype: Union[type, None]=None): \n",
        "    \"\"\"Scale a single Numpy array image intensity into range `0` and `1`\n",
        "    \"\"\"\n",
        "    min_val = np.min(image)\n",
        "    max_val = np.max(image)\n",
        "    image = (image - min_val) / (max_val - min_val)\n",
        "    if dtype:\n",
        "      image = image.astype(dtype)\n",
        "    return image\n",
        "\n",
        "def visualizer(slice: np.ndarray, title= ''): \n",
        "    \"\"\"Visualize a slice of type numpy array with the provided title.\"\"\"\n",
        "    plt.imshow(slice, cmap=plt.cm.bone)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "DpThAREoMvS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_slices_hu = to_hu(slices)\n",
        "processed_slices_cliped = window_clip(processed_slices_hu, 500, 1000) # Extracting soft tissues. \n",
        "image = to_3d_numpy(processed_slices_cliped, dtype=None)\n",
        "\n",
        "print('Numpy array image shape is: ', image.shape)\n",
        "print('Transformed image pixel value range (min, max): ', (image.min(), image.max()))\n",
        "\n",
        "scaled_image = min_max_scaler(image, dtype=np.float32)\n",
        "print('Scaled image pixel value range (min, max): ', (scaled_image.min(), scaled_image.max()))\n",
        "\n",
        "# You can see the scaled version of your slected region using the `window_clip` function here.\n",
        "visualizer(processed_slices_hu[10], 'HU transform')\n",
        "visualizer(scaled_image[10], 'Scaled')"
      ],
      "metadata": {
        "id": "YU7TcJkCW7dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3: Saving the data in numpy format\n",
        "* Convert original frames into a numpy image array without any preprocessing, and save it as a single `.npy` file named `original_numpy_version.npy`. Keeping the original slices as a 3d numpy sample in case we needed it in the future.\n",
        "* Create an ouput folder named `scaled_slices` and save all the scaled slices one by one into the folder. Assign a unique name to each slice while you are keeping the original order. "
      ],
      "metadata": {
        "id": "vPSuaw6NZ1nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the original slices into a 3d nmpy array and save it as a .npy file format. \n",
        "def to_3d_numpy(slices, output_file):\n",
        "    \n",
        "    # Sort the DICOM files by InstanceNumber\n",
        "    slices.sort(key=lambda x: pydicom.dcmread(x).InstanceNumber)\n",
        "\n",
        "    # Read the first DICOM file to get the shape of the pixel data\n",
        "    first_dicom = pydicom.dcmread(slices[0])\n",
        "    rows = int(first_dicom.Rows)\n",
        "    cols = int(first_dicom.Columns)\n",
        "    slices = len(slices)\n",
        "\n",
        "    # Create a 3D Numpy array to store the pixel data\n",
        "    pixel_data = np.zeros((slices, rows, cols), dtype=np.int16)\n",
        "\n",
        "    # Read the pixel data from each DICOM file and store it in the Numpy array\n",
        "    for i, file in enumerate(slices):\n",
        "        ds = pydicom.dcmread(file)\n",
        "        pixel_data[i, :, :] = ds.pixel_array\n",
        "\n",
        "    # Save the pixel data as a .npy file\n",
        "    np.save(output_file, pixel_data)\n",
        "\n",
        "    return pixel_data\n",
        "\n",
        "# Convert the DICOM files to a 3D Numpy array and save it as a .npy file\n",
        "pixel_data = to_3d_numpy(slices, \"pixel_data.npy\")\n"
      ],
      "metadata": {
        "id": "oRmK9A3b6y7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder and save the scaled slices one by one. \n",
        "# create the output directory if it doesn't exist\n",
        "if not os.path.exists('scaled_slices'):\n",
        "    os.makedirs('scaled_slices')\n",
        "\n",
        "# loop through the DICOM datasets and save them as individual slices\n",
        "for i, dataset in enumerate(scaled_image):\n",
        "    ds = pydicom.dataset.Dataset.from_dict({'PixelData': dataset.tobytes()})\n",
        "    filename = f'slice_{i}.dcm'\n",
        "    filepath = os.path.join('scaled_slices', filename)\n",
        "    pydicom.dcmwrite(filepath, ds)\n"
      ],
      "metadata": {
        "id": "Uri1gESq6y9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4: Save the processed numpy data as a series of DICOM files\n",
        "#### In this section, you need to save the scaled version image of the loaded dicom slices into a series of dicom files inside a directory named `scaled_slices_dicom`, be splitting the image into a sequence of slices in the original order.  \n",
        "To do so, you need to create a new dicom dataset for each slide, import the original dicom information into the new created dataset, and save it with a unique name inside the mentioned directory."
      ],
      "metadata": {
        "id": "TO1Z0iab_W-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the output directory if it doesn't exist\n",
        "if not os.path.exists('scaled_slices_dicom'):\n",
        "    os.makedirs('scaled_slices_dicom')\n",
        "\n",
        "# read the DICOM series into a list of slices\n",
        "slices = []\n",
        "for filename in os.listdir(dir_path):\n",
        "    filepath = os.path.join(dir_path, filename)\n",
        "    ds = pydicom.dcmread(filepath)\n",
        "    slices.append(ds.pixel_array)\n",
        "\n",
        "# convert the list of slices to a numpy array and scale the pixel values\n",
        "image = np.array(slices)\n",
        "scaled_image = (image - np.min(image)) / (np.max(image) - np.min(image)) * 65535\n",
        "scaled_image = scaled_image.astype(np.uint16)\n",
        "\n",
        "# loop through the slices and save them as individual DICOM files\n",
        "for i, slice_data in enumerate(scaled_image):\n",
        "    ds = pydicom.dataset.Dataset.from_dict({'PixelData': slice_data.tobytes()})\n",
        "    # set the DICOM attributes here, like the pixel spacing, etc.\n",
        "    # ...\n",
        "    filename = f'slice_{i}.dcm'\n",
        "    filepath = os.path.join('scaled_slices_dicom', filename)\n",
        "    pydicom.dcmwrite(filepath, ds)\n"
      ],
      "metadata": {
        "id": "Y3MscdDjKkBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}